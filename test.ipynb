{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "serp_key = os.getenv(\"SERP_KEY\")\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERP_PAGE_LIMIT = 2\n",
    "data = {\n",
    "    \"title\": [],\n",
    "    \"company_name\": [],\n",
    "    \"location\": [],\n",
    "    \"via\": [],\n",
    "    \"description\": [],\n",
    "    \"salary\": [],\n",
    "    \"linkedin_link\": []\n",
    "}\n",
    "next_page_token = \"\"\n",
    "for i in range(SERP_PAGE_LIMIT):\n",
    "    params = {\n",
    "        \"engine\": \"google_jobs\",\n",
    "        \"q\": \"senior data scientist since yesterday in united states full time\",\n",
    "        \"google_domain\": \"google.com\",\n",
    "        \"gl\": \"us\",\n",
    "        \"hl\": \"en\",\n",
    "        \"api_key\": serp_key,\n",
    "        \"next_page_token\": next_page_token\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "\n",
    "    for job in results[\"jobs_results\"]:\n",
    "        linkedIn_flag = False\n",
    "        linkedIn_link = None\n",
    "        for option in job[\"apply_options\"]:\n",
    "            if option[\"title\"] == \"LinkedIn\":\n",
    "                linkedIn_flag = True\n",
    "                linkedIn_link = option[\"link\"]\n",
    "                break\n",
    "\n",
    "        if linkedIn_flag:\n",
    "            data[\"title\"].append(job[\"title\"])\n",
    "            data[\"company_name\"].append(job[\"company_name\"])\n",
    "            data[\"location\"].append(job[\"location\"])\n",
    "            data[\"via\"].append(job[\"via\"])\n",
    "            data[\"linkedin_link\"].append(linkedIn_link)\n",
    "\n",
    "            # Description\n",
    "            header = \" | \".join(f\"{key}: {value}\" for key, value in job[\"detected_extensions\"].items())\n",
    "            data[\"description\"].append(header + \"\\n\" + job[\"description\"])\n",
    "\n",
    "            # Salary\n",
    "            if \"salary\" in job[\"detected_extensions\"]:\n",
    "                data[\"salary\"].append(job[\"detected_extensions\"][\"salary\"])\n",
    "            else:\n",
    "                data[\"salary\"].append(None)\n",
    "\n",
    "        # Set next page token\n",
    "        next_page_token = results[\"serpapi_pagination\"][\"next_page_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create filename\n",
    "serp_filename = f\"serp_{today}.csv\"\n",
    "SERP_FOLDER = \"serp_extract\"\n",
    "# Save DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(len(df))\n",
    "df.to_csv(SERP_FOLDER + \"/\" + serp_filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(SERP_FOLDER + \"/\" + serp_filename)\n",
    "with open('resume.txt', 'r') as f:\n",
    "    resume_input = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your base prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are an expert job-matching assistant. Your task is to evaluate how well a given job description matches a candidate's resume using weighted criteria, reflecting what matters most to the candidate.\n",
    "\n",
    "The candidate is targeting **Senior Data Scientist roles**, has **2 years of experience**, and is looking for **individual contributor (IC) roles only**, with a **total compensation of $240,000 or more**. Analyze the match between the resume and job description using the following weighted criteria:\n",
    "\n",
    "---\n",
    "\n",
    "üîç Evaluation Criteria (with Weights):\n",
    "1. Role Fit (Responsibilities & Scope) ‚Äì Weight: 10  \n",
    "2. Experience Requirement (Must require at most 2 years experience with a Master's degree) ‚Äì Weight: 10  \n",
    "3. Growth & Learning Opportunities ‚Äì Weight: 9  \n",
    "4. Role Level (Must be IC; not managerial or senior managerial) ‚Äì Weight: 9  \n",
    "5. Team & Manager Quality (if mentioned) ‚Äì Weight: 8  \n",
    "6. Company Stability & Mission Fit ‚Äì Weight: 8  \n",
    "7. Compensation (Target: $240K+, estimate based on role and company if not present) ‚Äì Weight: 8  \n",
    "8. Work-Life Balance & Culture ‚Äì Weight: 7  \n",
    "9. Technical Stack Relevance ‚Äì Weight: 6  \n",
    "10. Location / Remote Flexibility ‚Äì Weight: 5  \n",
    "11. Perks & Benefits ‚Äì Weight: 3  \n",
    "12. Job Description Quality ‚Äì Weight: 2\n",
    "13. Distance from current location, less is better (Jersey City, NJ) - Weight: 7\n",
    "\n",
    "All ratings must be in the range of **1 to 10**, where 1 is very poor alignment and 10 is perfect alignment.\n",
    "\n",
    "---\n",
    "\n",
    "üì• Inputs:\n",
    "- Resume: {resume_input}  \n",
    "- Job Description: {job_description}  \n",
    "\n",
    "---\n",
    "\n",
    "üì§ Output Format:\n",
    "Respond **only with a valid JSON object** in the format below:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"criteria_ratings\": {{\n",
    "    \"role_fit\": {{\"rating\": X, \"weight\": 10}},\n",
    "    \"experience_requirement\": {{\"rating\": X, \"weight\": 10}},\n",
    "    \"growth_opportunities\": {{\"rating\": X, \"weight\": 9}},\n",
    "    \"role_level\": {{\"rating\": X, \"weight\": 9}},\n",
    "    \"team_quality\": {{\"rating\": X, \"weight\": 8}},\n",
    "    \"company_stability_mission\": {{\"rating\": X, \"weight\": 8}},\n",
    "    \"compensation\": {{\"rating\": X, \"weight\": 8}},\n",
    "    \"work_life_balance\": {{\"rating\": X, \"weight\": 7}},\n",
    "    \"tech_stack\": {{\"rating\": X, \"weight\": 6}},\n",
    "    \"location_remote\": {{\"rating\": X, \"weight\": 5}},\n",
    "    \"benefits\": {{\"rating\": X, \"weight\": 3}},\n",
    "    \"jd_quality\": {{\"rating\": X, \"weight\": 2}},\n",
    "    \"distance_jc\": {{\"rating\": X, \"weight\": 7}}\n",
    "  }},\n",
    "  \"reasoning\": \"2-3 lines, at most 150 words, summarizing the overall fit and justification for the final score.\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Respond only with a valid JSON object. Do not include any text, Markdown code block, or backticks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    # Fill in the prompt\n",
    "    filled_prompt = prompt_template.format(resume_input=resume_input, job_description=row['description'])\n",
    "\n",
    "    # Call the API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": filled_prompt}\n",
    "        ],\n",
    "        temperature=0.1  # lower temperature for more consistent structure\n",
    "    )\n",
    "\n",
    "    # Extract and parse the JSON output\n",
    "    response_text = response.choices[0].message.content\n",
    "    try:\n",
    "        result = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Could not parse JSON. Here's the raw output:\")\n",
    "        print(response_text)\n",
    "        continue  # skip this row\n",
    "    else:\n",
    "        # Flatten and add ratings and weights\n",
    "        total_score = 0\n",
    "        total_weight = 0\n",
    "\n",
    "        for criterion, values in result['criteria_ratings'].items():\n",
    "            rating = values.get('rating', 0)\n",
    "            weight = values.get('weight', 0)\n",
    "\n",
    "            # Store rating and weight in DataFrame\n",
    "            df.at[i, f'{criterion}_rating'] = rating\n",
    "            df.at[i, f'{criterion}_weight'] = weight\n",
    "\n",
    "            # Accumulate weighted score\n",
    "            total_score += rating * weight\n",
    "            total_weight += weight\n",
    "\n",
    "        # Add reasoning\n",
    "        df.at[i, 'reasoning'] = result.get('reasoning')\n",
    "\n",
    "        # Compute and add final weighted average score\n",
    "        final_score = total_score / total_weight if total_weight else 0\n",
    "        df.at[i, 'final_score'] = round(final_score, 2)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'outputs'\n",
    "output_filename = f\"output_{today}.xlsx\"\n",
    "\n",
    "# Current columns\n",
    "cols = list(df.columns)\n",
    "\n",
    "cols.remove('linkedin_link')\n",
    "cols.append('linkedin_link')\n",
    "df = df[cols]\n",
    "\n",
    "df['linkedin_link'] = df['linkedin_link'].apply(lambda x: f'=HYPERLINK(\"{x}\", \"{x}\")')\n",
    "df = df.sort_values(by='final_score', ascending=False, na_position='last')\n",
    "df.to_excel(OUTPUT_DIR + '/' + output_filename, sheet_name='Job_Match_Results', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71f90bbf1865cf2d379c69d6e3142ab0841280c66af7cab68e4750204473421d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
